{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a72dc6f",
   "metadata": {},
   "source": [
    "# Trie Project\n",
    "\n",
    "Note: Documentation and code are both included within this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a556eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42bc3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "\n",
    "    def __init__(self, myCharName):\n",
    "        # A trie node may always be associated with a character, except the Root Node\n",
    "        #initialized TrieNode class with charName and 3 other attributes\n",
    "        self.endToken = False  # True only when the node represents the end of the word\n",
    "        self.ChildNodes = {}  # dict with chars as keys and nodes as their respective values, wasn't able to work with lists\n",
    "        # this dict may only contain one char and node per run. Its node value contains its children\n",
    "        self.char = myCharName # setting the name character of this node\n",
    "        self.frequency = 0  # cumulative frequency initialized \n",
    "\n",
    "    def getNodeChar(self):\n",
    "        #This method simply returns its name character\n",
    "        return self.char\n",
    "\n",
    "    def getFrequency(self, substring):\n",
    "        #substring is a sliced or complete word that returns an int which is the substring's frequency\n",
    "        for char in substring:\n",
    "            if not self.getChildNode(char):\n",
    "                break\n",
    "            self = self.getChildNode(char)\n",
    "        return self.frequency\n",
    "\n",
    "    def getChildNode(self, childChar):\n",
    "        # searches through ChildNodes, if node with character 'childChar' is found then returns childNode\n",
    "        for i in self.ChildNodes:\n",
    "            if i == childChar:\n",
    "                return self.ChildNodes[childChar]\n",
    "        return None\n",
    "\n",
    "    def addEntry(self, substring, freq):\n",
    "        # Loop through each character in the word\n",
    "        # Check if there is no child containing the character, create a new child for the current node and store in ChildNode\n",
    "        # endToken will be True since we reach last character of the substring\n",
    "        for char in substring:\n",
    "            if self.getChildNode(char) == None:\n",
    "                self.ChildNodes[char] = TrieNode(char)\n",
    "            self = self.getChildNode(char)\n",
    "            self.frequency += freq\n",
    "        self.endToken = True\n",
    "#         print(substring, \"was added\", self.counter)\n",
    "        return True\n",
    "\n",
    "    def hasWord(self, substring):\n",
    "        #substring is iterated over to fetch  individual char\n",
    "        # if char is not there then return False, else update self, getChildNode\n",
    "        #returns endToken which will be True depending on the node's endToken value\n",
    "        for char in substring:\n",
    "            if self.getChildNode(char) == None:\n",
    "                return False\n",
    "            self = self.getChildNode(char)\n",
    "        return self.endToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b2bef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieDS:\n",
    "    def __init__(self):\n",
    "        #initialized TrieDS class with an instance of a trie node.\n",
    "        #Root nodes are empty and the first node of the trie structure.\n",
    "        print(\"I am the Root Node, I have no name\")\n",
    "        self.RootNode = TrieNode(\"\")  #create an instance node, but root has no character!\n",
    "\n",
    "    def addWord(self, word, frequency):\n",
    "        #word is a string to be added to current trie node instance and frequency passes an int value\n",
    "        return self.RootNode.addEntry(word, frequency)\n",
    "\n",
    "    def hasWord(self, word):\n",
    "        #word is a string stored in trie\n",
    "        #returns True if word is in trie, otherwise False\n",
    "        #print(f\"Checking {word} - {self.RootNode.hasWord(word)}\")\n",
    "        return self.RootNode.hasWord(word)\n",
    "\n",
    "    def getFrequency(self, word):\n",
    "        #here word is a string with corresponding frequency value \n",
    "        #Subtrings have frequencies as well, regardless of the boolean value of hasWord\n",
    "        #returns an int value in the string's frequency\n",
    "        return self.RootNode.getFrequency(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a026a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#created global variables outside of the functions/classes\n",
    "suffixes_r = dict() \n",
    "prefixes_r = dict() \n",
    "\n",
    "#function to slice strings to check boundary and perform boundary testing\n",
    "def getaffix(trieds, word):\n",
    "    #trieds populates the TrieDS object\n",
    "    #this function populates global variable dictionaries\n",
    "    for i, char in enumerate(word):\n",
    "        if i < (len(word) - 1):\n",
    "            stem = prefix = word[:i+1] # incase of reporters this would be 'r', 're'\n",
    "            suffix = end = word[i+1:] # incase of reporters this would be 'eporters', 'porters'\n",
    "            \n",
    "            #for suffixes\n",
    "            suffixes_r.setdefault(suffix, 0)  # default to 0 to avoid overwriting existing affixes,, gives werid error i can't figure out\n",
    "            if not trieds.hasWord(stem):  # Test1 to see if stem exists\n",
    "                suffixes_r[suffix] -= 1 #fails then -1\n",
    "            else:\n",
    "                suffix_testing = score_Suffix(stem, suffix, trieds) #if it exists then initializing score_Suffix method\n",
    "                suffixes_r[suffix] += suffix_testing.boundaryTests() #applying the remaining 2 tests frm within score_Suffix\n",
    "\n",
    "            # for prefixes\n",
    "            prefixes_r.setdefault(prefix, 0)\n",
    "            if not trieds.hasWord(end):\n",
    "                prefixes_r[prefix] -= 1\n",
    "            else:\n",
    "                prefix_testing = score_Prefix(prefix, end, trieds) #if it exists then initializing score_Prefix method\n",
    "                prefixes_r[prefix] += prefix_testing.boundaryTests() #applying the remaining 2 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e817b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class score_Suffix:\n",
    "    def __init__(self, stem, suffix, trie_ds):\n",
    "        #class for scoring suffixes initialized with a stem (alphaA), a suffix (Bbeta)\n",
    "        self.T = trie_ds #trie_ds is the TrieDS instance that is already populated\n",
    "        self.stem = stem\n",
    "        self.suffix = suffix\n",
    "\n",
    "    def getfreq(self):\n",
    "        #Builds alpha, alphaA and B frequency from stem and suffix\n",
    "        #returns ints. The frequencies corresponding to strings, alpha, alphaA, and alphaAB.\n",
    "        alphafreq = self.T.getFrequency(self.stem[:-1]) #apple = app--> stem[:-1]\n",
    "        alphaA_freq = self.T.getFrequency(self.stem) #stem is alphaA\n",
    "        Bfreq = self.T.getFrequency(self.stem + self.suffix[0]) #stem-->(alphaA) + [0] of suffix\n",
    "        return alphaA_freq, alphafreq, Bfreq\n",
    "\n",
    "# methods for testing\n",
    "# test2: probability has to be approx same\n",
    "# test3: probability has to be less than 1\n",
    "    def boundaryTest_2(self, freq1, freq2):\n",
    "        #returns True if resulting conditional probability is between 0.9 and 1\n",
    "        if freq2 == 0:\n",
    "            return -1\n",
    "        if 0.9 <= freq1 / freq2 <= 1:\n",
    "            return True\n",
    "\n",
    "    def boundaryTest_3(self, freq1, freq2):\n",
    "        #returns: True if resulting conditional probability is less than 1\n",
    "        if freq2 == 0:\n",
    "            return -1\n",
    "        if 0 <= freq1 / freq2 < 1:\n",
    "            return True\n",
    "\n",
    "    def boundaryTests(self):\n",
    "        #Calls self.getfreq to input ints to the boundary tests and change initialized score value\n",
    "        #returns the suffix score (int)\n",
    "        #frequencies[0]: alphaA freq value, frequencies[1]: alpha freq value, frequencies[2]: alphaAB freq value\n",
    "        frequencies = self.getfreq()\n",
    "        score = 0\n",
    "        # performs test and +19 if it passes -1 if it fails\n",
    "        if self.boundaryTest_2(frequencies[0], frequencies[1]) and self.boundaryTest_3(frequencies[2], frequencies[0]):\n",
    "            score += 19\n",
    "        else:\n",
    "            score = -1\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f92961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class score_Prefix(score_Suffix):\n",
    "\n",
    "    def __init__(self, prefix, stem, trie_ds):\n",
    "        #class for scoring prefixes initialized with a prefix (alphaA), a stem (Bbeta)\n",
    "        # get methods from score_Suffix, frequency values are from different sliced strings\n",
    "        self.T = trie_ds\n",
    "        self.prefix = prefix\n",
    "        self.stem = stem\n",
    "\n",
    "    def getfreq(self):\n",
    "        a_freq = self.T.getFrequency(self.prefix) #not sure? it would be prefix aka stem\n",
    "        beta_freq = self.T.getFrequency(self.prefix + self.stem)\n",
    "        b_freq = self.T.getFrequency(self.prefix + self.stem[0])\n",
    "        return beta_freq, b_freq, a_freq\n",
    "\n",
    "    def boundaryTests(self):\n",
    "        #same as above, just the frequencies being fed are different\n",
    "        frequencies = self.getfreq()\n",
    "        score = 0\n",
    "        if self.boundaryTest_2(frequencies[0], frequencies[1]) and self.boundaryTest_3(frequencies[0], frequencies[2]):\n",
    "            score += 19\n",
    "        else:\n",
    "            score = -1\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dcd87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_byvalue(d):\n",
    "    #d is the suffixes_r, prefixes_r\n",
    "    #returns a sorted affixes in descending order\n",
    "    return sorted(d.items(), key = lambda affix: affix[1], reverse = True)\n",
    "\n",
    "def rankwords(d):\n",
    "    #returns a list where negative values have been removed and the affixes have been sorted by the sort_byvalue function\n",
    "    return sort_byvalue(dict((i, j) for i, j in d.items() if j >= 0))\n",
    "    \n",
    "def topwords(d, percentage):\n",
    "    #percentage can be aything between 0 to 1 so, 10% is 0.1, etc.\n",
    "    #returns top affixes based on given percentage\n",
    "    return d[:round(percentage * len(d))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff38365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    word      Freq\n",
      "0    the  70922517\n",
      "1     of  40947787\n",
      "2    and  39196587\n",
      "3     to  36179805\n",
      "4      a  26456052\n",
      "5     in  23266319\n",
      "6     is  15205138\n",
      "7    for  13419393\n",
      "8   that  11574871\n",
      "10    on  10124216\n"
     ]
    }
   ],
   "source": [
    "# loading english_corpus txt file\n",
    "eng_df =  pd.read_csv(\"english_corpus.txt\", delimiter='\\t')\n",
    "eng_df.dropna(inplace=True)\n",
    "\n",
    "# only using words with freq > 10000 because it yields better results, got rid of one letter words and https links,\n",
    "#could've used a method to filter data better?? maybe later?\n",
    "#print(len(eng_df))\n",
    "eng_df = eng_df[eng_df[\"Freq\"] > 10000]\n",
    "eng_df.loc[:, \"word\"] = eng_df[\"word\"].str.lower() #everything to lowercase\n",
    "eng_df.drop_duplicates(subset=[\"word\"], keep=\"first\", inplace=True) #drop duplicates\n",
    "#checking for duplicate words, since before there was 'the' and 'The' twice and so on with other words!\n",
    "print(eng_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b314e4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am the Root Node, I have no name\n"
     ]
    }
   ],
   "source": [
    "MyTrie = TrieDS()\n",
    "\n",
    "eng_df.apply(lambda row: MyTrie.addWord(row[\"word\"], row[\"Freq\"]), axis=1) #applying addWord/ adding words to Trie\n",
    "eng_df.apply(lambda row: MyTrie.hasWord(row[\"word\"]), axis=1) #checking words on Trie\n",
    "eng_df.apply(lambda row: getaffix(MyTrie, row[\"word\"]), axis=1)\n",
    "\n",
    "\n",
    "#applying rankwords and topwords method to present top 10 % of leading affixes\n",
    "top_suffixes = topwords(rankwords(suffixes_r), 0.1)\n",
    "top_prefixes = topwords(rankwords(prefixes_r), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e58f4139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729\n",
      "Top suffixes: [('s', 14326), ('ed', 3480), ('ing', 2832), ('ly', 2270), ('d', 698), ('er', 592), ('al', 562), ('.', 400), ('ive', 384), ('ion', 354)]\n",
      "\n",
      "329\n",
      "Top prefixes: [('hi', 123), ('the', 113), ('ti', 113), ('back', 112), ('no', 111), ('bi', 107), ('dea', 106), ('out', 104), ('sa', 102), ('every', 95)]\n"
     ]
    }
   ],
   "source": [
    "print(len(top_suffixes))\n",
    "print('Top suffixes:', top_suffixes[:10])\n",
    "\n",
    "print()\n",
    "\n",
    "print(len(top_prefixes))\n",
    "print('Top prefixes:', top_prefixes[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca5119",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4f378",
   "metadata": {},
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f3bc52",
   "metadata": {},
   "source": [
    "### Assignment Discussion\n",
    "\n",
    "The above code consists of:\n",
    "\n",
    "#### ClassMethods:\n",
    "1. TrieNode class:\n",
    "    - Methods:\n",
    "        - getNodeChar():\n",
    "            - simply returns its name character\n",
    "        - getFrequency():\n",
    "            - accepts a sliced or complete word (substring) and returns an int value which is the substring's frequency\n",
    "        - getChildNode():\n",
    "            - searches through ChildNodes{}, if node with character 'childChar' is found then returns childNode\n",
    "        - addEntry():\n",
    "            - Loops through each character in the word(substring)\n",
    "            - Check if there is no child containing the character, create a new child for the current node and store in ChildNode\n",
    "            - adding words was here I got stuck the most in the beginning because I failed to realize that self needed to be updated within the loop. In this case, failing to update self(getChildNode) would result in empty outputs.    \n",
    "        - hasWord():\n",
    "            - substring is iterated over to fetch  individual char\n",
    "            - if char is not there then return False, else update self, getChildNode\n",
    "            - returns endToken which will be True depending on the node's endToken value\n",
    "            - has word was similar logic to addEntry so I did not have much problems with it\n",
    "\n",
    "\n",
    "2. TrieDS class: Experimented the TrieDS with goodwords and badwords, at first I was having trouble with confirming if hasWord was working since the method kept checking the words but would return false even though the word existed. I later figured out that the self was not being updated with every iteration and thus the method couldn't actually confirm the words.\n",
    "    - Methods:\n",
    "        - addWord():\n",
    "            - word is added to the trie node instance and frequency passes an int value\n",
    "        - hasWord():\n",
    "            - checks if word is in Trie and returns True or False accordingly\n",
    "        - getFrequency():\n",
    "            - gets word (either sliced or complete) with it's corresponding frequency value\n",
    "\n",
    "\n",
    "3. getaffix class:\n",
    "    - I first experimented on how to slice the strings in order to get the alpha, alphaA, alphaAB, etc. Tried using a brute force method such as:\n",
    " \n",
    "                - for i, char in enumerate(substring):\n",
    "                    if i < (len(substring) - 1):\n",
    "                        alpha = substring[:i]\n",
    "                         A = substring[i]\n",
    "                         B = substring[i+1]\n",
    "                         beta = substring[i+2:]\n",
    "                         stem = alpha + A\n",
    "                         suffix = B + beta\n",
    "                 - for i, char in enumerate(words):\n",
    "                        if i < (len(words) - 1):\n",
    "                        stem = prefix = words[:i+1]\n",
    "                        suffix = end = words[i+1:]\n",
    "                        # print('prefix')\n",
    "                        # print(prefix)\n",
    "                        # print('suffix')\n",
    "                        # print(suffix)\n",
    "                        prefix1 = stem[:-1]\n",
    "                        # print('new')\n",
    "                        # print(prefix1)\n",
    "                        B = stem + suffix[0]??\n",
    "                        print('Bbeta is:')\n",
    "                        print(B)??\n",
    "    - Used this logic to create the class and method and then performed Test 1 on both suffixes and prefixes.\n",
    "    - Test 1 is simply checking if alphaA, which is stem in case of suffix and end in case of prefix, is present using hasWord. If it passes the test then we apply the respective score_Suffix or score_Prefix method to perform the remaining tests. If it fails then -1. The prefixes and suffixes are loaded into the respective dictionaries.\n",
    "\n",
    "\n",
    "4. score_Suffix class:\n",
    "    - Methods:\n",
    "        - getfreq():\n",
    "            - Builds alpha, alphaA and B frequency from stem and suffix, and returns their corresponding int. value\n",
    "            - To do this the getFrequency method from TrieDS is applied to the stem and suffix\n",
    "        - boundaryTest_2():\n",
    "            - A conditionalProbability is applied to test whether the probability id between 0.9 and 1 since Test 2 requires for the the frequencies to be approximately same.\n",
    "            - The condition: if freq2 == 0: return -1 is applied since divions cannot happen with denominator as 0. If not for the condition then method would output ZeroDivisionError: division by zero.\n",
    "        - boundaryTest_3():\n",
    "            - A conditionalProbability is applied to test whether the probability id between 0 and 1, since it can't be negative. Test 3 requires for the the probability of frequencies to be less than 1.\n",
    "            - - The condition: if freq2 == 0: return -1 is applied since divions cannot happen with denominator as 0. If not for the condition then method would output ZeroDivisionError: division by zero.\n",
    "        - boundaryTests():\n",
    "            - This method simply gets the frequencies from the getfreq method and then applies boundaryTest_2 and boundaryTest_3 to ge the scores.\n",
    "\n",
    "\n",
    "5. score_Prefix class: this class got methods from score_Suffix, and is alsmost the same as score_Suffix except that we are working with different set of sliced strings and frequencies.\n",
    "    - Methods:\n",
    "         - getfreq():\n",
    "             - This methods is the same as above except the frequency are pulled from different sliced strings: prefix (alphaA), a stem (Bbeta)\n",
    "         - boundaryTests():\n",
    "             - This method is the same as the one in score_Suffix but with different frequencies.\n",
    "\n",
    "#### Functions:\n",
    "\n",
    "6. sort_byvalue:\n",
    "    - This function sorts the affixes in descending order using the sorted() method.\n",
    "7. rankwords: \n",
    "    - This function removes affixes with negative values and applies the sort_byvalue function.\n",
    "8. topwords:\n",
    "    - This function returns top affixes based on given percentage. It is a simple x% of len(d) function.\n",
    "    \n",
    "#### Data preprocessing:\n",
    "\n",
    "I had some problems reading the data in the beginning as the text file has some lines that did not work well with pandas implementation. So, I look at the text file and removed the '---' lines as well as the first few note lines so that i could read the file using pandas and get a simple dataframe. Then, upon inspection I saw that some of the words weren't really words but links and that some were repeated with upper and lower case letters. So, I performed some cleaning, changed all words to lowercase, filtered out words that had frequency lower than 10,000 and got rid of duplicates.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c41a4b",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "I applied the topwords method to the ranked suffixes and prefixes, to get the top 10% of the affixes. I got the following results:\n",
    "\n",
    "length of the top 10% of suffixes: 729\n",
    "\n",
    "Top suffixes[:10]: [('s', 14326), ('ed', 3480), ('ing', 2832), ('ly', 2270), ('d', 698), ('er', 592), ('al', 562), ('.', 400), ('ive', 384), ('ion', 354)]\n",
    "\n",
    "\n",
    "length of the top 10% of prefixes: 329\n",
    "\n",
    "Top prefixes[:10]: [('hi', 123), ('the', 113), ('ti', 113), ('back', 112), ('no', 111), ('bi', 107), ('dea', 106), ('out', 104), ('sa', 102), ('every', 95)]\n",
    "\n",
    "The suffixes seem to make sense and the fact that 'ing', 'ed', 'ly' are listed among the top tells me that the suffixes are computed well. The prefixes such as 'bi', 'out', 'every' were also good outcomes as they were listed high among the ranked prefixes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298bcb8",
   "metadata": {},
   "source": [
    "### Segmentation:\n",
    "\n",
    "I experimented with various methods for segmentation but struggled with 'TypeErrors', and couldn't figure out how to solve them correctly. The logic I tried to implement for segmentation was:\n",
    "- Loop over suffix from top_suffixes\n",
    "- Check if any of the stored words ends with the suffix\n",
    "- If yes then store them in the new dictionary\n",
    "- The use another loop to only fetch the most frequent words from within the dictionary\n",
    "\n",
    "This was the logic I intended to apply, I'm not sure if it would have worked but it seemed like the most simple way to implement segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f397af",
   "metadata": {},
   "source": [
    "### References\n",
    "- https://albertauyeung.github.io/2020/06/15/python-trie.html/\n",
    "- https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/22453/Lushtak_washington_0250O_11149.pdf?sequence=1\n",
    "- https://www.aleksandrhovhannisyan.com/blog/trie-data-structure-implementation-in-python/\n",
    "- https://slideplayer.com/slide/5016724/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
